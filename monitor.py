# monitor.py

import os
import re
import json
import logging
import requests

from datetime import datetime
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    ContextTypes,
)

import config

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Ğ¡ĞµÑÑĞ¸Ñ Ğ´Ğ»Ñ HTTP-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
session = requests.Session()
session.headers["User-Agent"] = "Mozilla/5.0"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_state() -> dict:
    """Ğ“Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ»ÑÑ‡Ğ¸ last_pdf Ğ¸ last_news_url."""
    if os.path.exists(config.STATE_FILE):
        st = json.load(open(config.STATE_FILE, "r", encoding="utf-8"))
    else:
        st = {}
    st.setdefault("last_pdf", None)
    st.setdefault("last_news_url", None)
    return st

def save_state(st: dict):
    with open(config.STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(st, f, ensure_ascii=False, indent=2)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_latest_pdf() -> tuple[str, str] | tuple[None, None]:
    resp = session.get(config.PAGE_URL)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    candidates = []
    for a in soup.find_all("a", href=True):
        m = re.search(r"(free_flats_(\d{8})\.pdf)$", a["href"])
        if not m:
            continue
        fn   = m.group(1)
        ds   = m.group(2)
        # Ğ¿Ğ°Ñ€ÑĞ¸Ğ¼ Ğ´Ğ°Ñ‚Ñƒ
        dt = None
        for fmt in ("%Y%m%d","%d%m%Y"):
            try:
                dt = datetime.strptime(ds, fmt)
                break
            except ValueError:
                continue
        if not dt:
            continue
        url = urljoin(config.BASE_URL, a["href"])
        candidates.append((dt, fn, url))

    if not candidates:
        return None, None
    # ÑĞ°Ğ¼Ğ°Ñ ÑĞ²ĞµĞ¶Ğ°Ñ Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğµ
    _, fname, furl = max(candidates, key=lambda x: x[0])
    return fname, furl

def fetch_latest_news() -> tuple[str, str] | tuple[None, None]:
    """
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ (title, absolute_url) Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸
    Ğ½Ğ° ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ Ñ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑĞ¼Ğ¸ (ÑĞ°Ğ¼Ğ°Ñ ÑĞ²ĞµĞ¶Ğ°Ñ ÑĞ²ĞµÑ€Ñ…Ñƒ).
    """
    resp = session.get(config.NEWS_PAGE_URL)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")

    a = soup.find("a", href=re.compile(r"^/novosti/"))
    if not a:
        return None, None

    title = a.get_text(strip=True)
    url   = urljoin(config.BASE_URL, a["href"])
    return title, url

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def scheduled_pdf(context: ContextTypes.DEFAULT_TYPE):
    st       = load_state()
    last_pdf = st["last_pdf"]

    fname, furl = fetch_latest_pdf()
    if not fname or fname == last_pdf:
        return

    # ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ
    local = os.path.join("downloads", fname)
    os.makedirs(os.path.dirname(local), exist_ok=True)
    logger.info(f"Downloading PDF {furl}")
    r = session.get(furl, stream=True)
    r.raise_for_status()
    with open(local, "wb") as f:
        for chunk in r.iter_content(32_768):
            f.write(chunk)

    # ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ + PDF
    await context.bot.send_message(
        chat_id=config.CHAT_ID,
        text="âœ… Ğ’Ñ‹ÑˆĞ»Ğ° Ğ½Ğ¾Ğ²Ğ°Ñ Ñ€ĞµĞ´Ğ°ĞºÑ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°"
    )
    await context.bot.send_document(
        chat_id=config.CHAT_ID,
        document=open(local, "rb")
    )
    logger.info(f"Sent PDF {fname}")

    st["last_pdf"] = fname
    save_state(st)

async def scheduled_news(context: ContextTypes.DEFAULT_TYPE):
    st           = load_state()
    last_news_url = st["last_news_url"]

    title, url = fetch_latest_news()
    if not url or url == last_news_url:
        return

    text = f"ğŸ“° ĞĞ¾Ğ²Ğ°Ñ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ:\n{title}\n{url}"
    await context.bot.send_message(chat_id=config.CHAT_ID, text=text)
    logger.info(f"Sent news {url}")

    st["last_news_url"] = url
    save_state(st)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def cmd_state(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    st = load_state()
    await update.message.reply_text(
        f"Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ:\n```json\n{json.dumps(st, indent=2, ensure_ascii=False)}\n```",
        parse_mode="MarkdownV2"
    )

async def cmd_start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¡Ğ»ĞµĞ¶Ñƒ Ğ·Ğ° PDF Ğ¸ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑĞ¼Ğ¸.\n"
        "ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹:\n"
        "/getpdf â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ PDF\n"
        "/getnews â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ\n"
        "/state â€” Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ"
    )

async def cmd_getpdf(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    fname, furl = fetch_latest_pdf()
    if not fname:
        return await update.message.reply_text("PDF Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½.")
    local = os.path.join("downloads", fname)
    os.makedirs(os.path.dirname(local), exist_ok=True)
    r = session.get(furl, stream=True)
    r.raise_for_status()
    with open(local, "wb") as f:
        for chunk in r.iter_content(32_768):
            f.write(chunk)
    await ctx.bot.send_message(chat_id=update.effective_chat.id,
                               text="âœ… Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ PDF:")
    await ctx.bot.send_document(chat_id=update.effective_chat.id,
                                document=open(local, "rb"))

async def cmd_getnews(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    title, url = fetch_latest_news()
    if not url:
        return await update.message.reply_text("ĞĞ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
    await ctx.bot.send_message(
        chat_id=update.effective_chat.id,
        text=f"ğŸ“° Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ÑŒ:\n{title}\n{url}"
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    app = (
        ApplicationBuilder()
        .token(config.BOT_TOKEN)
        .build()
    )

    jq = app.job_queue
    # Ñ€Ğ°ÑĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ PDF Ğ¸ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹
    jq.run_repeating(scheduled_pdf,
                     interval=config.CHECK_EVERY_MINUTES * 60,
                     first=5)
    jq.run_repeating(scheduled_news,
                     interval=config.NEWS_CHECK_INTERVAL * 60,
                     first=10)

    app.add_handler(CommandHandler("start",  cmd_start))
    app.add_handler(CommandHandler("state",  cmd_state))
    app.add_handler(CommandHandler("getpdf", cmd_getpdf))
    app.add_handler(CommandHandler("getnews",cmd_getnews))

    logger.info("Bot started, pollingâ€¦")
    app.run_polling()

if __name__ == "__main__":
    main()
